{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Lab2: Adversarial Attacks on Deep Neural Networks\n",
    "\n",
    "#### What has been done in this notebook:\n",
    "* Import the baseline classifier\n",
    "* Save the baseline classifier and re-trained classifier\n",
    "* All requirements in the lab instruction doc (instead of code submission instruction)\n",
    "\n",
    "#### The trained_model, trained by baseline classifier, has been used for:\n",
    "* FGSM Based Untargeted Attack\n",
    "* FGSM Based targeted Attack\n",
    "\n",
    "#### The re-trained classifier, trained using modified training set, has been used for:\n",
    "* Espilon = 10, FGSM Based Untargeted Attack\n",
    "* FGSM Based Untargeted Attack\n",
    "\n",
    "#### For code submission result evaluation, please check 'Result_Reproduction.ipynb'\n",
    "\n",
    "#### Don't interrupt the kernel. If have to interrupt, restart and clean output. Then run from beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 2\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b1 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "\n",
    "W3 = tf.Variable(tf.zeros([300, 10]))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#y_pred = tf.Variable(np.arange(3000), dtype=tf.float32, name=\"prediction\")\n",
    "\n",
    "# Construct model\n",
    "\n",
    "hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1); #first hidden layer\n",
    "\n",
    "#hidden2 = tf.nn.relu(tf.matmul(hidden1, W2) + b2); #second hidden layer\n",
    "\n",
    "pred = tf.nn.softmax(tf.matmul(hidden1, W3) + b3) # Softmax layer outputs prediction probabilities\n",
    "\n",
    "# Minimize error using cross entropy \n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "saver = tf.train.Saver()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.565998296\n",
      "Epoch: 0002 cost= 0.372614300\n",
      "Optimization Finished!\n",
      "Tensor(\"Mean_5:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Neg_3:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"strided_slice_73:0\", shape=(?,), dtype=float32)\n",
      "Accuracy: 0.875333\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "            \n",
    "#             print(__w)\n",
    "            \n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "#             print(sess.run(W))\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "    # Calculate accuracy for 3000 examples; you should get roughly ~90% accuracy although it might vary from run to run\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print (\"Accuracy:\", \n",
    "           accuracy.eval({x: mnist.test.images[:3000], \n",
    "                          y: mnist.test.labels[:3000]},\n",
    "                         session=sess))\n",
    "    \n",
    "    #Save the model\n",
    "    saver.save(sess, './temp/trained_model.ckpt')\n",
    "    print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to calculate success rate for both targeted and untargeted attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_success_rate(xts, xts_new, yts, target):\n",
    "    \n",
    "    # Result of old test data\n",
    "    prediction_old = tf.argmax(pred,1)\n",
    "    prediction_old = prediction_old.eval({x: xts})    \n",
    "    \n",
    "    correct_prediction = tf.equal(prediction_old, tf.argmax(yts, 1))\n",
    "    correct_prediction = correct_prediction.eval({x: xts})\n",
    "        \n",
    "    # Because we are only looking for sussessful rate\n",
    "    correct_prediction_index = np.where(correct_prediction)\n",
    "        \n",
    "    xts_correct = xts_new[correct_prediction_index,:]\n",
    "    xts_correct = xts_correct[0,:,:]\n",
    "        \n",
    "    correct_prediction = correct_prediction[correct_prediction_index]\n",
    "    prediction_old = prediction_old[correct_prediction_index]\n",
    "        \n",
    "    # Result of new test data\n",
    "    prediction_new = tf.argmax(pred,1)\n",
    "    prediction_new = prediction_new.eval({x:xts_correct})\n",
    "    \n",
    "    if target==None:\n",
    "        \n",
    "        # Find out which index of correct_predictions are changed after perturb\n",
    "        attack_success_index = np.not_equal(prediction_old, prediction_new)\n",
    "        \n",
    "    if target==True:\n",
    "        \n",
    "        yts_shift = np.roll(yts, 1, axis = 1)\n",
    "        yts_target = yts_shift[correct_prediction_index,:]\n",
    "        prediction_target = np.argmax(yts_target,2)\n",
    "        \n",
    "        # Find out which index of correct_predictions are changed to (i+1)%10 after perturb\n",
    "        attack_success_index = np.equal(prediction_target, prediction_new)\n",
    "        \n",
    "    # Calculaye attack ratio\n",
    "    attack_success_no = np.count_nonzero(attack_success_index)\n",
    "    correct_prediction_no = np.count_nonzero(correct_prediction)\n",
    "       \n",
    "    attack_success_rate = attack_success_no/correct_prediction_no\n",
    "    \n",
    "    return attack_success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM Based Untargeted Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from temp/trained_model.ckpt\n",
      "FGSM Attack!\n",
      "Tensor(\"strided_slice_74:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"gradients_61/MatMul_4_grad/MatMul:0\", shape=(?, 784), dtype=float32)\n",
      "Epsilon: 1 Attack success rate 0.0\n",
      "Tensor(\"strided_slice_75:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"gradients_62/MatMul_4_grad/MatMul:0\", shape=(?, 784), dtype=float32)\n",
      "Epsilon: 5 Attack success rate 0.0\n",
      "Tensor(\"strided_slice_76:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"gradients_63/MatMul_4_grad/MatMul:0\", shape=(?, 784), dtype=float32)\n",
      "Epsilon: 10 Attack success rate 0.0\n",
      "Tensor(\"strided_slice_77:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"gradients_64/MatMul_4_grad/MatMul:0\", shape=(?, 784), dtype=float32)\n",
      "Epsilon: 20 Attack success rate 0.0\n",
      "Tensor(\"strided_slice_78:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"gradients_65/MatMul_4_grad/MatMul:0\", shape=(?, 784), dtype=float32)\n",
      "Epsilon: 30 Attack success rate 0.0\n",
      "Tensor(\"strided_slice_79:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"gradients_66/MatMul_4_grad/MatMul:0\", shape=(?, 784), dtype=float32)\n",
      "Epsilon: 40 Attack success rate 0.0\n",
      "Tensor(\"strided_slice_80:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"gradients_67/MatMul_4_grad/MatMul:0\", shape=(?, 784), dtype=float32)\n",
      "Epsilon: 50 Attack success rate 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "xts = mnist.test.images\n",
    "yts = mnist.test.labels\n",
    "\n",
    "epsilon = np.array([1/256,5/256,10/256,20/256,30/256,40/256,50/256])\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if os.path.exists('temp/checkpoint'): \n",
    "        saver.restore(sess, 'temp/trained_model.ckpt')\n",
    "    \n",
    "    # FGSM Attack\n",
    "    print(\"FGSM Attack!\")\n",
    "\n",
    "    for eps in epsilon:\n",
    "        # Generate new test dataset\n",
    "        grad = tf.gradients(xs = x,\n",
    "                            ys = cost)\n",
    "        \n",
    "        xts_new = tf.clip_by_value(x + eps*tf.sign(grad),0,1)\n",
    "        xts_new, _ = sess.run([xts_new , cost], feed_dict={x: xts, y: yts})\n",
    "        xts_new = xts_new[0,:,:]\n",
    "         \n",
    "        rate = attack_success_rate(xts, xts_new, yts, None)\n",
    "    \n",
    "        print (\"Epsilon:\", \n",
    "               int(eps*256),\n",
    "               \"Attack success rate\",rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change digit i to (i+1)%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set axis=1, so right shift will be done to each row seperately(instead of whole matrix)\n",
    "\n",
    "yts_shift = np.roll(yts, 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if os.path.exists('temp/checkpoint'): \n",
    "        saver.restore(sess, 'temp/trained_model.ckpt')\n",
    "    \n",
    "    # FGSM Attack\n",
    "    print(\"FGSM Targeted Attack!\")\n",
    "\n",
    "    for eps in epsilon:\n",
    "        \n",
    "        # Generate new test dataset\n",
    "        grad = tf.gradients(xs = x,\n",
    "                            ys = cost)\n",
    "        \n",
    "        # Targeted Attack\n",
    "        xts_new2 = tf.clip_by_value(x - eps*tf.sign(grad),0,1)\n",
    "        xts_new2, _ = sess.run([xts_new2 , cost], feed_dict={x: xts, y: yts_shift})\n",
    "        xts_new2 = xts_new2[0,:,:]\n",
    "         \n",
    "        rate = attack_success_rate(xts, xts_new2, yts, True)\n",
    "        print(\"Epsilon:\", \n",
    "               int(eps*256),\n",
    "              \"Attack success rate\",\n",
    "              rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Retraining against Untargeted FGSM Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr = mnist.train.images\n",
    "ytr = mnist.train.labels\n",
    "\n",
    "eps = 10/256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a new version of 'next_batch' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch_new(batch_size, x, y):\n",
    "    \n",
    "    # Return a total of `num` random samples and labels. \n",
    "    idx = np.arange(0 , len(x))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:batch_size]\n",
    "    \n",
    "    x_shuffle = x[idx]\n",
    "    y_shuffle = y[idx]\n",
    "    \n",
    "    return np.asarray(x_shuffle), np.asarray(y_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #  Perturbs each image in training set        \n",
    "    grad = tf.gradients(xs = x, ys = cost)\n",
    "    xtr_perturb = tf.clip_by_value(x + eps*tf.sign(grad),0,1)\n",
    "    \n",
    "    xtr_perturb, _ = sess.run([xtr_perturb , cost], feed_dict={x: xtr, y: ytr})\n",
    "    xtr_perturb = xtr_perturb[0,:,:]\n",
    "\n",
    "    # Appends the adversarially perturbed images to original training set\n",
    "    xtr_new = np.vstack((xtr,xtr_perturb))\n",
    "    ytr_new = np.vstack((ytr,ytr))\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(xtr_new.shape[0]/batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = next_batch_new(batch_size, xtr_new, ytr_new)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                       y: batch_ys})\n",
    "\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "            \n",
    "    print (\"Optimization Finished!\")\n",
    "    \n",
    "    #Save the model\n",
    "    saver.save(sess, './temp/trained_model_new.ckpt')\n",
    "    print(\"Retraining model saved!\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy of the adversarially retrained DNN on the original test dataset that contains only clean inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if os.path.exists('temp/checkpoint'): \n",
    "        saver.restore(sess, 'temp/trained_model_new.ckpt')\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    # Calculate accuracy for 3000 examples; you should get roughly ~90% accuracy although it might vary from run to run\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    print ('\\nClassification accuracy of the adversarially retrained DNN on the original test dataset that contains only clean inputs:')\n",
    "    print (\"Accuracy:\", \n",
    "           accuracy.eval({x: xts, \n",
    "                          y: yts},\n",
    "                         session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement FGSM based untargeted attacks using images from the clean test set on the adversarially retrained DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Generate new test dataset\n",
    "    grad = tf.gradients(xs = x, ys = cost)\n",
    "    \n",
    "        \n",
    "    if os.path.exists('temp/checkpoint'): \n",
    "        saver.restore(sess, 'temp/trained_model_new.ckpt')\n",
    "    \n",
    "    xts_new = tf.clip_by_value(x + eps*tf.sign(grad),0,1)\n",
    "    xts_new, _ = sess.run([xts_new , cost], feed_dict={x: xts, y: yts})\n",
    "    xts_new = xts_new[0,:,:]\n",
    "         \n",
    "    rate = attack_success_rate(xts, xts_new, yts, None)\n",
    "    \n",
    "    print('\\nSuccess rate of FGSM untargeted attack on retrained DNN:')\n",
    "    \n",
    "    print (\"Epsilon:\", \n",
    "           int(eps*256),\n",
    "           \"Attack success rate\",rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Step 3 for different epsilons\n",
    "\n",
    "This operation takes much longer than above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for eps in epsilon:\n",
    "        \n",
    "        if os.path.exists('temp/checkpoint'): \n",
    "            saver.restore(sess, 'temp/trained_model_new.ckpt')\n",
    "                     \n",
    "        #  Perturbs each image in training set\n",
    "        xtr_perturb = tf.clip_by_value(x + eps*tf.sign(grad),0,1)\n",
    "        xtr_perturb, _ = sess.run([xtr_perturb , cost], \n",
    "                                  feed_dict={x: xtr, y: ytr})\n",
    "        xtr_perturb = xtr_perturb[0,:,:]\n",
    "\n",
    "        # Appends the adversarially perturbed images to original training set\n",
    "        xtr_new = np.vstack((xtr,xtr_perturb))\n",
    "        ytr_new = np.vstack((ytr,ytr))\n",
    "    \n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(xtr_new.shape[0]/batch_size)\n",
    "        \n",
    "            # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "                batch_xs, batch_ys = next_batch_new(batch_size, xtr_new, ytr_new)\n",
    "                # Fit training using batch data\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                       y: batch_ys})\n",
    "\n",
    "                # Compute average loss\n",
    "                avg_cost += c / total_batch\n",
    "                \n",
    "        print (\"Epsilon:\", int(eps*256))\n",
    "\n",
    "        grad = tf.gradients(xs = x,\n",
    "                            ys = cost)\n",
    "        \n",
    "        xts_new = tf.clip_by_value(x + eps*tf.sign(grad),0,1)\n",
    "        xts_new, _ = sess.run([xts_new , cost], feed_dict={x: xts, y: yts})\n",
    "        xts_new = xts_new[0,:,:]\n",
    "         \n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        print (\"Accuracy:\", \n",
    "               accuracy.eval({x: xts_new, \n",
    "                              y: yts},\n",
    "                             session=sess))\n",
    "        \n",
    "        rate = attack_success_rate(xts, xts_new, yts, None)\n",
    "        print (\"Attack success rate\",rate,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
