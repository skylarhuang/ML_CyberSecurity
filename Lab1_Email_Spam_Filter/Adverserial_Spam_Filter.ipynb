{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-mail Spam Filtering Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "#Simple NB Based Lingspam Spam classifier \n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets as skd\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "#Each sub-directory in the parent directory is assumed to contain documents from the same class\n",
    "#I pre-processed the part1 (fold1) and part2 (fold2) of the lingspam dataset to place spam emails in one folder \n",
    "#and legit emails in another; you should do the same for the entire dataset, either manually or via a script. \n",
    "ls_train = skd.load_files('./data/lingspam_public/lemm_stop/train');\n",
    "ls_test = skd.load_files('./data/lingspam_public/lemm_stop/test');\n",
    "\n",
    "#The count vectorizer classes fit_transform function generates a vocoabulary that contains each unique term in the dataset\n",
    "#and outputs a sparse matrix tabulating term occurences\n",
    "count_vect = CountVectorizer(binary=True)\n",
    "x_train = count_vect.fit_transform(ls_train.data)\n",
    "\n",
    "#Since the vocabulary has already been learned, use the transform function to transform the test data using the same vocab\n",
    "x_test = count_vect.transform(ls_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare\n",
    "num_email = x_train.shape[0]\n",
    "num_feature = x_train.shape[1]\n",
    "\n",
    "# Transport saved data from sparse matrix out\n",
    "x_train_data = x_train.toarray()\n",
    "x_train_ig = np.zeros([num_feature])\n",
    "\n",
    "for i in range(num_feature):\n",
    "    \n",
    "    # Each colunm show the occurence of one feature in all emails\n",
    "    feature_vector = x_train_data[:,i]\n",
    "    \n",
    "    # Reshape \n",
    "    feature_vector = feature_vector.reshape([num_email])\n",
    "    \n",
    "    # Calculate ig for features \n",
    "    x_train_ig [i] = mutual_info_score(feature_vector, ls_train.target)\n",
    "\n",
    "# Use sorting function to sort the ig array, add minus '-' for descending order \n",
    "x_train_ig_sort = np.argsort(-x_train_ig)\n",
    "\n",
    "# Extract feature names\n",
    "name_feature = count_vect.get_feature_names()\n",
    "\n",
    "# Select N largest features' index\n",
    "N = 10\n",
    "top_feature = np.array(x_train_ig_sort[:N])\n",
    "drop_feature = np.array(x_train_ig_sort[N:num_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_feature(ls_train, ls_test):\n",
    "    # Use the count vectorizer classes to get binary featrues\n",
    "    # Set parmeter 'binary' to True, all non zero counts are set to 1\n",
    "    count_vect_bf = CountVectorizer(binary=True)\n",
    "    \n",
    "    x_train_bf = count_vect_bf.fit_transform(ls_train.data)\n",
    "    x_test_bf  = count_vect_bf.transform(ls_test.data)\n",
    "    \n",
    "    # Still drop the unwanted features in training set\n",
    "    x_train_bf = x_train_bf[:, top_feature]\n",
    "    x_test_bf  = x_test_bf[:, top_feature]\n",
    "    \n",
    "    return x_train_bf, x_test_bf\n",
    "\n",
    "x_train_bf, x_test_bf = binary_feature(ls_train, ls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "\n",
    "def pre_rec(yts, yhat):\n",
    "    precision, recall, f1,_ = precision_recall_fscore_support(yts,\n",
    "                                                              yhat,\n",
    "                                                              average='binary')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Classifier\n",
      "Precision = 0.888889\n",
      "Recall= 0.816327\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB with BF features\n",
    "mNomBF = sklearn.naive_bayes.MultinomialNB()\n",
    "mNomBF.fit(x_train_bf,ls_train.target)\n",
    "\n",
    "y_predict_M_BF = mNomBF.predict(x_test_bf)\n",
    "\n",
    "pre,rec = pre_rec(ls_test.target, y_predict_M_BF)\n",
    "\n",
    "print('Original Classifier')\n",
    "print('Precision = {0:f}'.format(pre))\n",
    "print('Recall= {0:f}'.format(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the log_odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x_spam = 0\n",
    "num_x_legit = 0\n",
    "num_spam_add = 0\n",
    "num_legit_add = 0\n",
    "\n",
    "for i in range(N):\n",
    "    num_spam_add = np.count_nonzero((x_test_bf.toarray()[:,i])&(y_predict_M_BF==1))\n",
    "    num_legit_add = np.count_nonzero((x_test_bf.toarray()[:,i])&(y_predict_M_BF==0))\n",
    "    \n",
    "    num_x_spam = num_x_spam + num_spam_add\n",
    "    num_x_legit = num_x_legit + num_legit_add\n",
    "\n",
    "def log_odds(i, x, y_predict):\n",
    "    \n",
    "    num_spam  = np.count_nonzero(y_predict==1)\n",
    "    num_legit = np.count_nonzero(y_predict==0)\n",
    "    \n",
    "    num_xi_spam  = np.count_nonzero(x[:,i]&(y_predict_M_BF==1))\n",
    "    num_xi_legit = np.count_nonzero(x[:,i]&(y_predict_M_BF==0))\n",
    "    \n",
    "    log_odd = np.log((num_xi_spam+1/num_x_spam+N)/(num_xi_legit+1/num_x_legit+N))\n",
    "    \n",
    "    return log_odd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find featrues with contribution to legit probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th feature could help the attackers.\n",
      "It has 49 unit cost in test set.\n",
      "The 3th feature could help the attackers.\n",
      "It has 49 unit cost in test set.\n",
      "The 4th feature could help the attackers.\n",
      "It has 48 unit cost in test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaos\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "x_test_init = count_vect.transform(ls_test.data)[:, top_feature]\n",
    "x_test_temp = count_vect.transform(ls_test.data)[:, top_feature]\n",
    "\n",
    "log_delta = 0\n",
    "cost = []\n",
    "edit_feature = []\n",
    "ind_spam = np.array(ls_test.target==1)\n",
    "num_spam = np.count_nonzero(ls_test.target==1)\n",
    "\n",
    "for i,feature_ind in enumerate(top_feature):\n",
    "    \n",
    "    log_1 = log_odds(i,x_test_bf.toarray(),y_predict_M_BF)\n",
    "    \n",
    "    x_test_temp[:,i] = 1\n",
    "    y_predict_temp = mNomBF.predict(x_test_temp)\n",
    "    log_2 = log_odds(i,x_test_temp.toarray(),y_predict_temp)\n",
    "    \n",
    "    delta_log = log_1 - log_2\n",
    "    costi = np.count_nonzero(x_test_init.toarray()[ind_spam,i] == 0)\n",
    "\n",
    "    if (((delta_log)<=0)):\n",
    "        cost.append(costi)\n",
    "        edit_feature.append(i)\n",
    "        \n",
    "        print('The ' + str(i) + 'th feature could help the attackers.')\n",
    "        print('It has ' + str(costi) + ' unit cost in test set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Gray Code to generate possible modified vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy.combinatorics.graycode import GrayCode\n",
    "\n",
    "a = GrayCode(3)\n",
    "y = list(a.generate_gray())\n",
    "\n",
    "z = np.zeros([8,3])\n",
    "for i in range(8):\n",
    "    z[i,:] = list(y[i])\n",
    "\n",
    "z.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaos\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.]\n",
      "Precision is 0.0\n"
     ]
    }
   ],
   "source": [
    "cost_all = np.sum(cost)\n",
    "\n",
    "for i in range(len(z)):\n",
    "    \n",
    "    x_test_new_i = count_vect.transform(ls_test.data)[:, top_feature]\n",
    "    \n",
    "    x_test_new_i[ind_spam,0] = z[i,0]\n",
    "    x_test_new_i[ind_spam,3] = z[i,1]\n",
    "    x_test_new_i[ind_spam,4] = z[i,2]\n",
    "    \n",
    "    \n",
    "    y_predict = mNomBF.predict(x_test_new_i)\n",
    "    \n",
    "    pre, rec = pre_rec(ls_test.target,y_predict)\n",
    "    cost_edit = np.sum(np.dot(z[i,0], cost))\n",
    "    \n",
    "    if (pre==0):\n",
    "        if cost_edit <= cost_all:\n",
    "            print(z[i])\n",
    "            print('Precision is ' + str(pre))\n",
    "            cost_all = cost_edit\n",
    "    \n",
    "    if ((i==8)&(pre!=0)):\n",
    "        print('No answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified the test set and predict it with original classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negative Rate Before Modification = 0.183673\n",
      "False Negative Rate After  Modification = 1.000000\n",
      "Minimum unit cost to fool the spam filter is 2.97959183673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaos\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "x_test_new_attack = count_vect.transform(ls_test.data)[:, top_feature]\n",
    "x_test_new_attack[ind_spam,0] = 1\n",
    "x_test_new_attack[ind_spam,3] = 1\n",
    "x_test_new_attack[ind_spam,4] = 1\n",
    "\n",
    "y_predict_attack = mNomBF.predict(x_test_new_attack)\n",
    "\n",
    "fn = np.count_nonzero((ls_test.target==1) & (y_predict_M_BF==0))/num_spam\n",
    "fn_attack = np.count_nonzero((ls_test.target==1) & (y_predict_attack==0))/num_spam\n",
    "\n",
    "print('False Negative Rate Before Modification = {0:f}'.format(fn))\n",
    "print('False Negative Rate After  Modification = {0:f}'.format(fn_attack))\n",
    "print('Minimum unit cost to fool the spam filter is '+ str(cost_edit/num_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Update\n",
    "Adding new edited spam emails to the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "spam_email = x_test_bf.toarray()[ind_spam]\n",
    "spam_email_target = ls_test.target[ind_spam]\n",
    "\n",
    "x_train_bf_new = count_vect.transform(ls_train.data)[:, top_feature]\n",
    "x_train_bf_new = np.vstack((x_train_bf.toarray(),spam_email))\n",
    "\n",
    "ls_train_new = np.hstack((ls_train.target,spam_email_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the original filter agian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negative After Update = 0.0248914739679\n",
      "False Positive After Update = 0.0101858419634\n",
      "Classifier Accuracy = 0.966037735849\n"
     ]
    }
   ],
   "source": [
    "fn_update = []\n",
    "fp_update = []\n",
    "acc_update = []\n",
    "\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold,shuffle=True)\n",
    "\n",
    "for train, test in kf.split(x_train_bf_new):\n",
    "    Xtr = x_train_bf_new[train,:]\n",
    "    Xts = x_train_bf_new[test,:]\n",
    "    ytr = ls_train_new[train]\n",
    "    yts = ls_train_new[test]\n",
    "\n",
    "    mNomBF.fit(Xtr,ytr)\n",
    "\n",
    "    yhat = mNomBF.predict(Xts)\n",
    "    \n",
    "    fn_update.append(np.mean((yts==1) & (yhat==0)))\n",
    "    fp_update.append(np.mean((yts==0) & (yhat==1)))\n",
    "    acc_update = np.mean(np.mean((yts==yhat)))\n",
    "\n",
    "fn_update = np.mean(fn_update)\n",
    "fp_update = np.mean(fp_update)\n",
    "acc_update = np.mean(acc_update)\n",
    "\n",
    "print('False Negative After Update = ' + str(fn_update))\n",
    "print('False Positive After Update = ' + str(fp_update))\n",
    "print('Classifier Accuracy = ' + str(acc_update)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
